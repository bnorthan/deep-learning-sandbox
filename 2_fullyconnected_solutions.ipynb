{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = '../data/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAJZCAYAAAC5o3GSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b863df8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "start=841\n",
    "\n",
    "letters=['a','b','c','d','e','f','g','h','i','j']\n",
    "\n",
    "def plot_results(start, images, labels, result=None):\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "\n",
    "    i=331\n",
    "    \n",
    "    for num in range(start, start+9):\n",
    "        plt.subplot(i)\n",
    "        i=i+1\n",
    "        plt.imshow(images[num,:], cmap='gray',interpolation='none')\n",
    "        \n",
    "        label=letters[labels[num]]\n",
    "        if (result!=None):\n",
    "            label=label+\" (\"+letters[result[num]]+\")\"\n",
    "        plt.title(label)\n",
    "        \n",
    "plot_results(start, train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19723,
     "status": "ok",
     "timestamp": 1449847956364,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "2ba0fc75-1487-4ace-a562-cf81cae82793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set and labels (200000, 784) (200000, 10)\n",
      "Validation set and labels (10000, 784) (10000, 10)\n",
      "Test set and labels (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "print('Training set and labels', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set and labels', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set and labels', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCLVqyQ5vPPH"
   },
   "source": [
    "We're first going to train a multinomial logistic regression using simple gradient descent.\n",
    "\n",
    "TensorFlow works like this:\n",
    "* First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:\n",
    "\n",
    "      with graph.as_default():\n",
    "          ...\n",
    "\n",
    "* Then you can run the operations on this graph as many times as you want by calling `session.run()`, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:\n",
    "\n",
    "      with tf.Session(graph=graph) as session:\n",
    "          ...\n",
    "\n",
    "Let's load all the data into TensorFlow and build the computation graph corresponding to our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([Dimension(784), Dimension(10)])\n",
      "TensorShape([Dimension(10)])\n",
      "\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "num=10000\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "tf_valid_dataset = tf.constant(valid_dataset)\n",
    "tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "print (weights.get_shape())\n",
    "print (biases.get_shape())\n",
    "\n",
    "logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "\n",
    "test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n",
    "\n",
    "\n",
    "\n",
    "print (\"\")\n",
    "print (type(tf_train_dataset))\n",
    "print (type(weights))\n",
    "print (type(biases))\n",
    "print (type(logits))\n",
    "print (type(loss))\n",
    "\n",
    "graph_test=tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Nfv39qvtvOl_"
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random valued following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQcL4uqISHjP"
   },
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 9
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 57454,
     "status": "ok",
     "timestamp": 1449847994134,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "z2cjdenH869W",
    "outputId": "4c037ba1-b526-4d8e-e632-91e2a0333267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 20.522234\n",
      "Training accuracy: 8.4%\n",
      "Validation accuracy: 10.1%\n",
      "Loss at step 100: 2.369557\n",
      "Training accuracy: 70.5%\n",
      "Validation accuracy: 71.3%\n",
      "Loss at step 200: 1.865223\n",
      "Training accuracy: 74.0%\n",
      "Validation accuracy: 73.8%\n",
      "Loss at step 300: 1.602354\n",
      "Training accuracy: 75.6%\n",
      "Validation accuracy: 74.5%\n",
      "Loss at step 400: 1.432487\n",
      "Training accuracy: 76.6%\n",
      "Validation accuracy: 74.9%\n",
      "Loss at step 500: 1.309320\n",
      "Training accuracy: 77.5%\n",
      "Validation accuracy: 75.2%\n",
      "Loss at step 600: 1.213897\n",
      "Training accuracy: 78.1%\n",
      "Validation accuracy: 75.4%\n",
      "Loss at step 700: 1.136799\n",
      "Training accuracy: 78.6%\n",
      "Validation accuracy: 75.5%\n",
      "Loss at step 800: 1.072803\n",
      "Training accuracy: 79.1%\n",
      "Validation accuracy: 75.7%\n",
      "Test accuracy: 83.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x68f-hxRGm3H"
   },
   "source": [
    "Let's now switch to stochastic gradient descent training instead, which is much faster.\n",
    "\n",
    "The graph will be similar, except that instead of holding all the training data into a constant node, we create a `Placeholder` node which will be fed actual data at every call of `sesion.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "qhPMzWYRGrzM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmVZESmtG4JH"
   },
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 66292,
     "status": "ok",
     "timestamp": 1449848003013,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "FoF91pknG_YW",
    "outputId": "d255c80e-954d-4183-ca1c-c7333ce91d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 14.272486\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 15.0%\n",
      "Minibatch loss at step 500: 2.004512\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 1000: 1.954158\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1500: 1.538984\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 2000: 0.934243\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2500: 0.820971\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3000: 0.823600\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 78.3%\n",
      "Test accuracy: 85.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units (nn.relu()) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "hidden_size = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_l1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, hidden_size]))\n",
    "  biases_l1 = tf.Variable(tf.zeros([hidden_size]))\n",
    "    \n",
    "  weights_l2=tf.Variable(tf.truncated_normal([hidden_size,num_labels]))\n",
    "  biases_l2=tf.Variable(tf.zeros([num_labels]))\n",
    "                        \n",
    "  hidden_l1=tf.nn.relu(tf.matmul(tf_train_dataset, weights_l1)+biases_l1)\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(hidden_l1, weights_l2) + biases_l2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_l1)+biases_l1), weights_l2) + biases_l2)\n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_l1)+biases_l1), weights_l2) + biases_l2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 275.797180\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 24.5%\n",
      "Minibatch loss at step 500: 15.159262\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1000: 9.547112\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 10.541299\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 2000: 3.839437\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 2500: 4.637244\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 4.186859\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.8%\n",
      "Test accuracy: 88.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
